{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdef481",
   "metadata": {},
   "source": [
    "# Positive and Unlabeled Learning\n",
    "### simulating unlabeled data in the breast cancer data set, then building a classifer using propensity\n",
    "\n",
    "Uses Selected at Random Assumption and propensity. Adapted from \"Machine Learning from Weak Supervision\"\n",
    "https://mitpress.mit.edu/9780262047074/machine-learning-from-weak-supervision/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d74a16",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04ecfa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score,accuracy_score,roc_auc_score\n",
    "\n",
    "\n",
    "# Propensity Ops functions\n",
    "from propensity_ops import estimate_propensity_scores, compute_class_weights, train_pu_model, calculate_optimal_threshold\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06153a80",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1575ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_column_type(df):\n",
    "    categorical_columns = []\n",
    "    continuous_columns = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            categorical_columns.append(column)\n",
    "        elif pd.api.types.is_numeric_dtype(df[column]):\n",
    "            unique_values = df[column].nunique()\n",
    "            if unique_values < 10:  # Adjust this threshold as needed\n",
    "                categorical_columns.append(column)\n",
    "            else:\n",
    "                continuous_columns.append(column)\n",
    "        else:\n",
    "            # Handle other data types if necessary\n",
    "            pass\n",
    "\n",
    "    return categorical_columns, continuous_columns\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5838e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4310ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('malware.csv', sep =\"|\")\n",
    "categorical_columns, continuous_columns = determine_column_type(data)\n",
    "\n",
    "df_categorical = data[categorical_columns]\n",
    "df_continuous = data[continuous_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839b4e6",
   "metadata": {},
   "source": [
    "# scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baf6fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the continuous DataFrame\n",
    "df_continuous_scaled = pd.DataFrame(scaler.fit_transform(df_continuous), columns=df_continuous.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "730b93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['legitimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2e19a",
   "metadata": {},
   "source": [
    "# split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719675b",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y =df_continuous_scaled ,data['legitimate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e71582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (110437, 49)\n",
      "Validation set size: (13805, 49)\n",
      "Testing set size: (13805, 49)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and temporary sets (80% training, 20% temporary)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df_continuous_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and testing sets (50% validation, 50% testing)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53526674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77474\n",
       "1    32963\n",
       "Name: legitimate, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268d32c",
   "metadata": {},
   "source": [
    "# hide 80 % of the labels so unlabeled and negative labels are grouped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77ea64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(X_train)) < 0.75\n",
    "y_train = y_train.values\n",
    "y_train[mask]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52044482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maskv = np.random.rand(len(X_val)) < 0.75\n",
    "y_val = y_val\n",
    "y_val[maskv]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ecd79f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    102371\n",
       "1      8066\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3586ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a99669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04024aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09220a28",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df2f4d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:39:25.719611Z",
     "start_time": "2024-03-19T14:39:25.676261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drdre\\.conda\\envs\\tensorflowcpu_20220413\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\drdre\\.conda\\envs\\tensorflowcpu_20220413\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Estimate propensity scores\n",
    "propensity_scores = estimate_propensity_scores(X_train, y_train)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weights(y_train, propensity_scores)\n",
    "\n",
    "# Train the PU model\n",
    "pu_model = train_pu_model(X_train, y_train, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b09600e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pu_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f5d9fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06643274853801169, 0.7109018471568272)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred),accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44e82260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9672,    0],\n",
       "       [3991,  142]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93604ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probsv=pu_model.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a8640fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs=pu_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9d185",
   "metadata": {},
   "source": [
    "\n",
    "# Function to find the optimal threshold\n",
    "\n",
    "\n",
    "# Find the optimal threshold\n",
    "\n",
    "\n",
    "# Apply the optimal threshold to make final predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57745521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.08\n",
      "Best F1 score: 0.36597049243150026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to find the optimal threshold\n",
    "def find_optimal_threshold(y_true, y_probs):\n",
    "    thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "    f1_scores = [f1_score(y_true, y_probs >= t) for t in thresholds]\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold, max(f1_scores)\n",
    "\n",
    "# Find the optimal threshold\n",
    "optimal_threshold, best_f1_score = find_optimal_threshold(y_val, y_probsv)\n",
    "print(\"Optimal threshold:\", optimal_threshold)\n",
    "print(\"Best F1 score:\", best_f1_score)\n",
    "\n",
    "# Apply the optimal threshold to make final predictions\n",
    "y_preds = (y_probs >= optimal_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c00a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283451133317085"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "579397da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574067366896052"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce34cd",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfe05319",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs=pu_model.predict_proba(X_test)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "176e8bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853668510047535"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fcbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
